<h1>ğŸŒŸ MoodMirror â€“ A Real-Time Mental Health Companion</h1>

  ![image url](https://github.com/SasankaDinith/ICTMiniproject/blob/main/Homepage.png?raw=true)


  <h2>ğŸ“– Introduction</h2>
    <p>
      University students often face stress, anxiety, and emotional burnout without having proper mechanisms to monitor 
      and regulate their mental well-being. Existing tools are usually reactive, impersonal, or lack engagement.
    </p>
    <p>
      <strong>MoodMirror</strong> is an AI-powered real-time mental health companion that detects emotions through 
      <em>facial expressions, speech tone, and body language</em> and provides personalized wellness feedback. 
      The system is designed to act as a â€œsmart mirrorâ€ or desktop/web application that promotes daily self-reflection 
      and emotional awareness for students.
    </p>

  <h2>ğŸ¯ Project Objectives</h2>
    <ul>
      <li>Detect student moods using AI-based multimodal emotion recognition.</li>
      <li>Provide real-time wellness feedback and personalized resources.</li>
      <li>Create a simple, engaging interface that encourages regular use.</li>
      <li>Support stress relief through recommendations like music, exercises, and relaxation tips.</li>
    </ul>

   <h2>ğŸ› ï¸ Features</h2>
    <ul>
      <li><strong>Facial Emotion Recognition</strong> (happy, sad, angry, neutral, etc.)</li>
      <li><strong>Speech Tone Analysis</strong> for stress and mood detection</li>
      <li><strong>Real-Time Feedback</strong> with mental wellness tips</li>
      <li><strong>Personalized Recommendations</strong> (music, relaxation techniques, motivational quotes)</li>
      <li><strong>User-Friendly Interface</strong> designed for students</li>
    </ul>

  <h2>ğŸ“ System Architecture</h2>
    <ul>
      <li>UI/UX design : https://www.figma.com/design/zwxWXTzoAwqcu60RMMwfpQ/Untitled?node-id=0-1&m=dev&t=vr5nlyllMSYMsFCe-1</li>
      <li><strong>Frontend:</strong> React / Web-based UI (User Interaction)</li>
      <li><strong>Backend:</strong> NodeJs, ExpressJS for emotion detection APIs</li>
      <li><strong>AI Models:</strong> OpenCV, Transfomers, PIL, torch libraries for emotion & speech analysis</li>
      <li><strong>Database:</strong> MySQL / MongoDB (optional for storing sessions)</li>
    </ul>

  <h2>ğŸ§ª Testing Process</h2>
    <ul>
      <li><strong>Unit Testing:</strong> Emotion detection models tested independently</li>
      <li><strong>Integration Testing:</strong> Backend + UI interactions verified</li>
      <li><strong>User Testing:</strong> Peer evaluation of usability and accuracy</li>
      <li><strong>Performance Testing:</strong> API response time and detection speed measured</li>
    </ul>


  <h2>ğŸš€ Future Enhancements</h2>
    <ul>
      <li>Mobile application version</li>
      <li>Expanded emotion categories (boredom, surprise, etc.)</li>
      <li>Daily mood tracking with analytics</li>
      <li>Integration with campus wellness services</li>
    </ul>

  <h2>ğŸ“Œ License</h2>
    <p>
      This project is developed as part of our <strong>3rd Year University Group Project</strong> 
      at the <em>University of Sri Jayewardenepura</em>.
    </p>


  </div>
</body>
</html>
